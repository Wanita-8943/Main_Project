{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ow7eWoNw6U-c"
      },
      "source": [
        "#เรียกใช้ CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "z8o_VVNXzcL8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1_2Fe8u81d5r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ac0cb67-f8f1-45ae-f03f-6d13101e443a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mbLFqTO1ze9O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "c3cf3428-f881-4737-811e-96912c85f43b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Fig_Age  Fig_Person_Sex  Age(year) Class  Class_Re       Filename  \\\n",
              "0           1               1          7   Y07         0         V1.jpg   \n",
              "1           2               1          7   Y07         0    Flip_V1.jpg   \n",
              "2           3               2          7   Y07         0         V2.jpg   \n",
              "3           4               2          7   Y07         0    Flip_V2.jpg   \n",
              "4           5               3          7   Y07         0         V3.jpg   \n",
              "...       ...             ...        ...   ...       ...            ...   \n",
              "4745      121              77         25   Y25        18  Flip_J463.jpg   \n",
              "4746      122              78         25   Y25        18       J464.jpg   \n",
              "4747      123              78         25   Y25        18  Flip_J464.jpg   \n",
              "4748      124              79         25   Y25        18       J465.jpg   \n",
              "4749      125              79         25   Y25        18  Flip_J465.jpg   \n",
              "\n",
              "                                          Path_filename     Sex Floder  \n",
              "0     /content/drive/My Drive/TVT_All_Age/train/Y07/...  Female   Both  \n",
              "1     /content/drive/My Drive/TVT_All_Age/train/Y07/...  Female   Both  \n",
              "2     /content/drive/My Drive/TVT_All_Age/train/Y07/...  Female   Both  \n",
              "3     /content/drive/My Drive/TVT_All_Age/train/Y07/...  Female   Both  \n",
              "4     /content/drive/My Drive/TVT_All_Age/train/Y07/...  Female   Both  \n",
              "...                                                 ...     ...    ...  \n",
              "4745  /content/drive/My Drive/TVT_All_Age/test/Y25/F...    Male   Both  \n",
              "4746  /content/drive/My Drive/TVT_All_Age/test/Y25/J...    Male   Both  \n",
              "4747  /content/drive/My Drive/TVT_All_Age/test/Y25/F...    Male   Both  \n",
              "4748  /content/drive/My Drive/TVT_All_Age/test/Y25/J...    Male   Both  \n",
              "4749  /content/drive/My Drive/TVT_All_Age/test/Y25/F...    Male   Both  \n",
              "\n",
              "[4750 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d4e036db-4a02-4791-88a5-1c7d2560c55e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fig_Age</th>\n",
              "      <th>Fig_Person_Sex</th>\n",
              "      <th>Age(year)</th>\n",
              "      <th>Class</th>\n",
              "      <th>Class_Re</th>\n",
              "      <th>Filename</th>\n",
              "      <th>Path_filename</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Floder</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07</td>\n",
              "      <td>0</td>\n",
              "      <td>V1.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_All_Age/train/Y07/...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07</td>\n",
              "      <td>0</td>\n",
              "      <td>Flip_V1.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_All_Age/train/Y07/...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07</td>\n",
              "      <td>0</td>\n",
              "      <td>V2.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_All_Age/train/Y07/...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07</td>\n",
              "      <td>0</td>\n",
              "      <td>Flip_V2.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_All_Age/train/Y07/...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07</td>\n",
              "      <td>0</td>\n",
              "      <td>V3.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_All_Age/train/Y07/...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4745</th>\n",
              "      <td>121</td>\n",
              "      <td>77</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25</td>\n",
              "      <td>18</td>\n",
              "      <td>Flip_J463.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_All_Age/test/Y25/F...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4746</th>\n",
              "      <td>122</td>\n",
              "      <td>78</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25</td>\n",
              "      <td>18</td>\n",
              "      <td>J464.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_All_Age/test/Y25/J...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4747</th>\n",
              "      <td>123</td>\n",
              "      <td>78</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25</td>\n",
              "      <td>18</td>\n",
              "      <td>Flip_J464.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_All_Age/test/Y25/F...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4748</th>\n",
              "      <td>124</td>\n",
              "      <td>79</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25</td>\n",
              "      <td>18</td>\n",
              "      <td>J465.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_All_Age/test/Y25/J...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4749</th>\n",
              "      <td>125</td>\n",
              "      <td>79</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25</td>\n",
              "      <td>18</td>\n",
              "      <td>Flip_J465.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_All_Age/test/Y25/F...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4750 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d4e036db-4a02-4791-88a5-1c7d2560c55e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d4e036db-4a02-4791-88a5-1c7d2560c55e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d4e036db-4a02-4791-88a5-1c7d2560c55e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "df = pd.read_csv (r'/content/drive/MyDrive/cut_panoramic/Data/New_All_Age_0.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qxePnnn7TGW"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "D-hCRloc3t39"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RooqSdBc7QHC"
      },
      "source": [
        "#กำหนดค่าพารามิเตอร์\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "thDb7U9B3xOo"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "width = 150\n",
        "height = 150\n",
        "epochs = 250\n",
        "NUM_TRAIN = 2850\n",
        "NUM_TEST = 950\n",
        "dropout_rate = 0.2\n",
        "input_shape = (height, width, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pumGmy6f3eSW"
      },
      "source": [
        "#Clone efficientnet repo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7iy2f8n16p0",
        "outputId": "d124a4d6-5619-4cc4-8e76-a7370f259e3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'efficientnet_keras_transfer_learning'...\n",
            "remote: Enumerating objects: 1079, done.\u001b[K\n",
            "remote: Counting objects: 100% (242/242), done.\u001b[K\n",
            "remote: Compressing objects: 100% (121/121), done.\u001b[K\n",
            "remote: Total 1079 (delta 121), reused 241 (delta 121), pack-reused 837\u001b[K\n",
            "Receiving objects: 100% (1079/1079), 13.94 MiB | 7.93 MiB/s, done.\n",
            "Resolving deltas: 100% (618/618), done.\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ],
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Gqg_EUxrKkcK"
      },
      "outputs": [],
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "uhCmH24AKmQ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a46701b5-720f-41b6-b9c3-ce909c815945"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b0_imagenet_1000_notop.h5\n",
            "16717576/16717576 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "yWNKfQUt5rga"
      },
      "outputs": [],
      "source": [
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.GlobalMaxPooling2D(name=\"gap\"))\n",
        "# model.add(layers.Flatten(name=\"flatten\"))\n",
        "if dropout_rate > 0:\n",
        "    model.add(layers.Dropout(dropout_rate, name=\"dropout_out\"))\n",
        "# model.add(layers.Dense(256, activation='relu', name=\"fc1\"))\n",
        "model.add(layers.Dense(19, activation='softmax', name=\"fc_out\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NadBB12251jh",
        "outputId": "2422c24a-c133-4b2a-b61a-66677d1ff302"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 19)                24339     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,073,903\n",
            "Trainable params: 4,031,887\n",
            "Non-trainable params: 42,016\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GepWq3yy53t5",
        "outputId": "74d1cf6b-3b3f-4f53-a56f-5c9753bf33cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the number of trainable layers before freezing the conv base: 213\n",
            "This is the number of trainable layers after freezing the conv base: 2\n"
          ]
        }
      ],
      "source": [
        "print('This is the number of trainable layers '\n",
        "      'before freezing the conv base:', len(model.trainable_weights))\n",
        "\n",
        "conv_base.trainable = False\n",
        "\n",
        "print('This is the number of trainable layers '\n",
        "      'after freezing the conv base:', len(model.trainable_weights))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIWHby0gKpEq",
        "outputId": "ac1a748b-3fd5-437a-eae7-7eb4f8d7305a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnet-b0\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 75, 75, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 75, 75, 32)  128         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " swish (Swish)                  (None, 75, 75, 32)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 75, 75, 32)  288         ['swish[0][0]']                  \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 75, 75, 32)  128         ['depthwise_conv2d[0][0]']       \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_1 (Swish)                (None, 75, 75, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 1, 1, 32)     0           ['swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 1, 1, 8)      264         ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " swish_2 (Swish)                (None, 1, 1, 8)      0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 1, 1, 32)     288         ['swish_2[0][0]']                \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 1, 1, 32)     0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 75, 75, 32)   0           ['activation[0][0]',             \n",
            "                                                                  'swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 75, 75, 16)   512         ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 75, 75, 16)  64          ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 75, 75, 96)   1536        ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 75, 75, 96)  384         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_3 (Swish)                (None, 75, 75, 96)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 38, 38, 96)  864         ['swish_3[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 38, 38, 96)  384         ['depthwise_conv2d_1[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_4 (Swish)                (None, 38, 38, 96)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 1, 1, 96)     0           ['swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 1, 1, 4)      388         ['lambda_1[0][0]']               \n",
            "                                                                                                  \n",
            " swish_5 (Swish)                (None, 1, 1, 4)      0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 1, 1, 96)     480         ['swish_5[0][0]']                \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 1, 1, 96)     0           ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 38, 38, 96)   0           ['activation_1[0][0]',           \n",
            "                                                                  'swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 38, 38, 24)   2304        ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 38, 38, 144)  3456        ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_6 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 38, 38, 144)  1296       ['swish_6[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 38, 38, 144)  576        ['depthwise_conv2d_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_7 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 1, 1, 144)    0           ['swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 1, 1, 6)      870         ['lambda_2[0][0]']               \n",
            "                                                                                                  \n",
            " swish_8 (Swish)                (None, 1, 1, 6)      0           ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_8[0][0]']                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 1, 1, 144)    0           ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 38, 38, 144)  0           ['activation_2[0][0]',           \n",
            "                                                                  'swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 38, 38, 24)   3456        ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_11[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " drop_connect (DropConnect)     (None, 38, 38, 24)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 38, 38, 24)   0           ['drop_connect[0][0]',           \n",
            "                                                                  'batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 38, 38, 144)  3456        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_12[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_9 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 19, 19, 144)  3600       ['swish_9[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 19, 19, 144)  576        ['depthwise_conv2d_3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_10 (Swish)               (None, 19, 19, 144)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 1, 1, 144)    0           ['swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 1, 1, 6)      870         ['lambda_3[0][0]']               \n",
            "                                                                                                  \n",
            " swish_11 (Swish)               (None, 1, 1, 6)      0           ['conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_11[0][0]']               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 1, 1, 144)    0           ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 19, 19, 144)  0           ['activation_3[0][0]',           \n",
            "                                                                  'swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 19, 19, 40)   5760        ['multiply_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 19, 19, 40)  160         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 19, 19, 240)  9600        ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 19, 19, 240)  960        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_12 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 19, 19, 240)  6000       ['swish_12[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 19, 19, 240)  960        ['depthwise_conv2d_4[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_13 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_4 (Lambda)              (None, 1, 1, 240)    0           ['swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_4[0][0]']               \n",
            "                                                                                                  \n",
            " swish_14 (Swish)               (None, 1, 1, 10)     0           ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_14[0][0]']               \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 1, 1, 240)    0           ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)          (None, 19, 19, 240)  0           ['activation_4[0][0]',           \n",
            "                                                                  'swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 19, 19, 40)   9600        ['multiply_4[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 19, 19, 40)  160         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_1 (DropConnect)   (None, 19, 19, 40)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 19, 19, 40)   0           ['drop_connect_1[0][0]',         \n",
            "                                                                  'batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 19, 19, 240)  9600        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 19, 19, 240)  960        ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_15 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 10, 10, 240)  2160       ['swish_15[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 10, 10, 240)  960        ['depthwise_conv2d_5[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_16 (Swish)               (None, 10, 10, 240)  0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_5 (Lambda)              (None, 1, 1, 240)    0           ['swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_5[0][0]']               \n",
            "                                                                                                  \n",
            " swish_17 (Swish)               (None, 1, 1, 10)     0           ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_17[0][0]']               \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 1, 1, 240)    0           ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 10, 10, 240)  0           ['activation_5[0][0]',           \n",
            "                                                                  'swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 10, 10, 80)   19200       ['multiply_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 10, 10, 80)  320         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 10, 10, 480)  38400       ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_18 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_18[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_6[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_19 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_6 (Lambda)              (None, 1, 1, 480)    0           ['swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_6[0][0]']               \n",
            "                                                                                                  \n",
            " swish_20 (Swish)               (None, 1, 1, 20)     0           ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_20[0][0]']               \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 1, 1, 480)    0           ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 10, 10, 480)  0           ['activation_6[0][0]',           \n",
            "                                                                  'swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 10, 10, 80)  320         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_2 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_2[0][0]',         \n",
            "                                                                  'batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 10, 10, 480)  38400       ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_21 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_21[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_7[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_22 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_7 (Lambda)              (None, 1, 1, 480)    0           ['swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_7[0][0]']               \n",
            "                                                                                                  \n",
            " swish_23 (Swish)               (None, 1, 1, 20)     0           ['conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_23[0][0]']               \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 1, 1, 480)    0           ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)          (None, 10, 10, 480)  0           ['activation_7[0][0]',           \n",
            "                                                                  'swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_7[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 10, 10, 80)  320         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_3 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_3[0][0]',         \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 10, 10, 480)  38400       ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_24 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_8 (DepthwiseC  (None, 10, 10, 480)  12000      ['swish_24[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_8[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_25 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_8 (Lambda)              (None, 1, 1, 480)    0           ['swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_8[0][0]']               \n",
            "                                                                                                  \n",
            " swish_26 (Swish)               (None, 1, 1, 20)     0           ['conv2d_33[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_26[0][0]']               \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 1, 1, 480)    0           ['conv2d_34[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_8 (Multiply)          (None, 10, 10, 480)  0           ['activation_8[0][0]',           \n",
            "                                                                  'swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 10, 10, 112)  53760       ['multiply_8[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 10, 10, 112)  448        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 10, 10, 672)  75264       ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_27 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_9 (DepthwiseC  (None, 10, 10, 672)  16800      ['swish_27[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_9[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_28 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_9 (Lambda)              (None, 1, 1, 672)    0           ['swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_9[0][0]']               \n",
            "                                                                                                  \n",
            " swish_29 (Swish)               (None, 1, 1, 28)     0           ['conv2d_37[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_29[0][0]']               \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 1, 1, 672)    0           ['conv2d_38[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_9 (Multiply)          (None, 10, 10, 672)  0           ['activation_9[0][0]',           \n",
            "                                                                  'swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_9[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 10, 10, 112)  448        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_4 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_4[0][0]',         \n",
            "                                                                  'batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 10, 10, 672)  75264       ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_30 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_10 (Depthwise  (None, 10, 10, 672)  16800      ['swish_30[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_10[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_31 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_10 (Lambda)             (None, 1, 1, 672)    0           ['swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_10[0][0]']              \n",
            "                                                                                                  \n",
            " swish_32 (Swish)               (None, 1, 1, 28)     0           ['conv2d_41[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_32[0][0]']               \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 1, 1, 672)    0           ['conv2d_42[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_10 (Multiply)         (None, 10, 10, 672)  0           ['activation_10[0][0]',          \n",
            "                                                                  'swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_10[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 10, 10, 112)  448        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_5 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_5[0][0]',         \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 10, 10, 672)  75264       ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_33 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_11 (Depthwise  (None, 5, 5, 672)   16800       ['swish_33[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 5, 5, 672)   2688        ['depthwise_conv2d_11[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_34 (Swish)               (None, 5, 5, 672)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_11 (Lambda)             (None, 1, 1, 672)    0           ['swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_11[0][0]']              \n",
            "                                                                                                  \n",
            " swish_35 (Swish)               (None, 1, 1, 28)     0           ['conv2d_45[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_35[0][0]']               \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 1, 1, 672)    0           ['conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_11 (Multiply)         (None, 5, 5, 672)    0           ['activation_11[0][0]',          \n",
            "                                                                  'swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 5, 5, 192)    129024      ['multiply_11[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 5, 5, 192)   768         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 5, 5, 1152)   221184      ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_36 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_12 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_36[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_12[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_37 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_12 (Lambda)             (None, 1, 1, 1152)   0           ['swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_12[0][0]']              \n",
            "                                                                                                  \n",
            " swish_38 (Swish)               (None, 1, 1, 48)     0           ['conv2d_49[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_38[0][0]']               \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_50[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_12 (Multiply)         (None, 5, 5, 1152)   0           ['activation_12[0][0]',          \n",
            "                                                                  'swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_12[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 5, 5, 192)   768         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_6 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_6[0][0]',         \n",
            "                                                                  'batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_39 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_13 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_39[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_13[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_40 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_13 (Lambda)             (None, 1, 1, 1152)   0           ['swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_13[0][0]']              \n",
            "                                                                                                  \n",
            " swish_41 (Swish)               (None, 1, 1, 48)     0           ['conv2d_53[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_41[0][0]']               \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_54[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_13 (Multiply)         (None, 5, 5, 1152)   0           ['activation_13[0][0]',          \n",
            "                                                                  'swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_13[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 5, 5, 192)   768         ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_7 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_7[0][0]',         \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_42 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_14 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_42[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_14[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_43 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_14 (Lambda)             (None, 1, 1, 1152)   0           ['swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_14[0][0]']              \n",
            "                                                                                                  \n",
            " swish_44 (Swish)               (None, 1, 1, 48)     0           ['conv2d_57[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_44[0][0]']               \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_58[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_14 (Multiply)         (None, 5, 5, 1152)   0           ['activation_14[0][0]',          \n",
            "                                                                  'swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_14[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 5, 5, 192)   768         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_8 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_8[0][0]',         \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_45 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_15 (Depthwise  (None, 5, 5, 1152)  10368       ['swish_45[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_15[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_46 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_15 (Lambda)             (None, 1, 1, 1152)   0           ['swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_15[0][0]']              \n",
            "                                                                                                  \n",
            " swish_47 (Swish)               (None, 1, 1, 48)     0           ['conv2d_61[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_47[0][0]']               \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_62[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_15 (Multiply)         (None, 5, 5, 1152)   0           ['activation_15[0][0]',          \n",
            "                                                                  'swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 5, 5, 320)    368640      ['multiply_15[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 5, 5, 320)   1280        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 5, 5, 1280)   409600      ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 5, 5, 1280)  5120        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_48 (Swish)               (None, 5, 5, 1280)   0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,049,564\n",
            "Trainable params: 0\n",
            "Non-trainable params: 4,049,564\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "conv_base.summary() #ดู Summary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "Uj7nbQgSco7g",
        "outputId": "098b91ca-8fea-46c7-d0fe-e2abda18d803",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 19)                24339     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,073,903\n",
            "Trainable params: 24,339\n",
            "Non-trainable params: 4,049,564\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J36J9EAE7qSB"
      },
      "source": [
        "#สร้างโฟลเดอร์ Train Valodation และ Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "nqCFbjRQ3okB"
      },
      "outputs": [],
      "source": [
        "base_dir = '/content/drive/MyDrive/TVT_All_Age'\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# Directories for our training,\n",
        "# validation and test splits\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "os.makedirs(validation_dir, exist_ok=True)\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.makedirs(test_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWEnlTSwazL5"
      },
      "source": [
        "\n",
        "#Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGPrsn9no_pa",
        "outputId": "241a1776-09fb-427c-ba11-2d6e3b83bcc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2850 images belonging to 19 classes.\n",
            "Found 950 images belonging to 19 classes.\n"
          ]
        }
      ],
      "source": [
        "# Train ด้วย ImageDataGenerator ของ Keras ซึ่งจะเพิ่มข้อมูลเสริมระหว่างการฝึกเพื่อลดโอกาสเกิด overfitting\n",
        "#overfitting เกิดจากข้อมูลที่ซับซ้อนกันเกินไป\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, #โมเดลส่วนใหญ่ต้องใช้ RGB ในช่วง 0–1\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory #ไดเรกเป้าหมาย\n",
        "        train_dir,\n",
        "        # รูปภาพทั้งหมดจะถูกปรับขนาดตามความสูงและความกว้างของเป้าหมาย\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "        #เนื่องจากเราใช้ categorical_crossentropy loss เราจึงต้องมีป้ายกำกับตามหมวดหมู่\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory( #การดึงภาพจาก Directory มาเข้าโมเดล \n",
        "        validation_dir,\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6qUmmF856ZE",
        "outputId": "6cdeaa68-6231-4cfb-bc44-5462c31a1f13"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-18-95ae5648fc7b>:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "178/178 [==============================] - 201s 1s/step - loss: 4.7772 - acc: 0.0526 - val_loss: 4.0174 - val_acc: 0.0487\n",
            "Epoch 2/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 4.1688 - acc: 0.0522 - val_loss: 3.8773 - val_acc: 0.0456\n",
            "Epoch 3/250\n",
            "178/178 [==============================] - 19s 107ms/step - loss: 4.0259 - acc: 0.0628 - val_loss: 3.8891 - val_acc: 0.0434\n",
            "Epoch 4/250\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 3.9757 - acc: 0.0526 - val_loss: 3.7787 - val_acc: 0.0477\n",
            "Epoch 5/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 3.9320 - acc: 0.0579 - val_loss: 3.7295 - val_acc: 0.0466\n",
            "Epoch 6/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 3.8292 - acc: 0.0752 - val_loss: 3.6759 - val_acc: 0.0477\n",
            "Epoch 7/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 3.7863 - acc: 0.0720 - val_loss: 3.5890 - val_acc: 0.0487\n",
            "Epoch 8/250\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 3.7610 - acc: 0.0780 - val_loss: 3.5488 - val_acc: 0.0477\n",
            "Epoch 9/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 3.6795 - acc: 0.0819 - val_loss: 3.4733 - val_acc: 0.0551\n",
            "Epoch 10/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 3.6880 - acc: 0.0699 - val_loss: 3.4219 - val_acc: 0.0551\n",
            "Epoch 11/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 3.6407 - acc: 0.0932 - val_loss: 3.3606 - val_acc: 0.0551\n",
            "Epoch 12/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 3.5928 - acc: 0.0829 - val_loss: 3.3109 - val_acc: 0.0657\n",
            "Epoch 13/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 3.6377 - acc: 0.0812 - val_loss: 3.2715 - val_acc: 0.0667\n",
            "Epoch 14/250\n",
            "178/178 [==============================] - 18s 101ms/step - loss: 3.5234 - acc: 0.0932 - val_loss: 3.2452 - val_acc: 0.0742\n",
            "Epoch 15/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 3.5592 - acc: 0.0808 - val_loss: 3.2098 - val_acc: 0.0805\n",
            "Epoch 16/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 3.4754 - acc: 0.0875 - val_loss: 3.1749 - val_acc: 0.0869\n",
            "Epoch 17/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 3.4357 - acc: 0.1006 - val_loss: 3.1472 - val_acc: 0.0900\n",
            "Epoch 18/250\n",
            "178/178 [==============================] - 19s 105ms/step - loss: 3.4287 - acc: 0.0963 - val_loss: 3.1248 - val_acc: 0.0911\n",
            "Epoch 19/250\n",
            "178/178 [==============================] - 19s 102ms/step - loss: 3.4717 - acc: 0.0896 - val_loss: 3.0744 - val_acc: 0.0932\n",
            "Epoch 20/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 3.4285 - acc: 0.1048 - val_loss: 3.0825 - val_acc: 0.0953\n",
            "Epoch 21/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 3.3267 - acc: 0.0974 - val_loss: 3.0618 - val_acc: 0.1017\n",
            "Epoch 22/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 3.3750 - acc: 0.0953 - val_loss: 3.0414 - val_acc: 0.0985\n",
            "Epoch 23/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 3.4163 - acc: 0.0924 - val_loss: 3.0336 - val_acc: 0.0996\n",
            "Epoch 24/250\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 3.3610 - acc: 0.0963 - val_loss: 2.9909 - val_acc: 0.1017\n",
            "Epoch 25/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 3.3041 - acc: 0.1020 - val_loss: 2.9814 - val_acc: 0.1059\n",
            "Epoch 26/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 3.2936 - acc: 0.1122 - val_loss: 2.9628 - val_acc: 0.1081\n",
            "Epoch 27/250\n",
            "178/178 [==============================] - 20s 108ms/step - loss: 3.3192 - acc: 0.1027 - val_loss: 2.9645 - val_acc: 0.1112\n",
            "Epoch 28/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 3.2595 - acc: 0.1150 - val_loss: 2.9497 - val_acc: 0.1123\n",
            "Epoch 29/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 3.2401 - acc: 0.1207 - val_loss: 2.9280 - val_acc: 0.1165\n",
            "Epoch 30/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 3.2780 - acc: 0.1073 - val_loss: 2.9075 - val_acc: 0.1123\n",
            "Epoch 31/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 3.2673 - acc: 0.1076 - val_loss: 2.9071 - val_acc: 0.1144\n",
            "Epoch 32/250\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 3.2227 - acc: 0.1129 - val_loss: 2.8947 - val_acc: 0.1155\n",
            "Epoch 33/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 3.2280 - acc: 0.1147 - val_loss: 2.8669 - val_acc: 0.1197\n",
            "Epoch 34/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 3.2156 - acc: 0.1122 - val_loss: 2.8558 - val_acc: 0.1197\n",
            "Epoch 35/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 3.1864 - acc: 0.1207 - val_loss: 2.8594 - val_acc: 0.1155\n",
            "Epoch 36/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 3.2035 - acc: 0.1217 - val_loss: 2.8476 - val_acc: 0.1165\n",
            "Epoch 37/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 3.2153 - acc: 0.1171 - val_loss: 2.8353 - val_acc: 0.1250\n",
            "Epoch 38/250\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 3.1668 - acc: 0.1186 - val_loss: 2.8274 - val_acc: 0.1208\n",
            "Epoch 39/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 3.1322 - acc: 0.1210 - val_loss: 2.8242 - val_acc: 0.1218\n",
            "Epoch 40/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 3.1331 - acc: 0.1203 - val_loss: 2.8269 - val_acc: 0.1239\n",
            "Epoch 41/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 3.1284 - acc: 0.1228 - val_loss: 2.8323 - val_acc: 0.1250\n",
            "Epoch 42/250\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 3.1552 - acc: 0.1186 - val_loss: 2.8251 - val_acc: 0.1229\n",
            "Epoch 43/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 3.0995 - acc: 0.1217 - val_loss: 2.8098 - val_acc: 0.1261\n",
            "Epoch 44/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 3.0748 - acc: 0.1299 - val_loss: 2.8041 - val_acc: 0.1250\n",
            "Epoch 45/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 3.1144 - acc: 0.1217 - val_loss: 2.7812 - val_acc: 0.1239\n",
            "Epoch 46/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 3.1253 - acc: 0.1203 - val_loss: 2.7767 - val_acc: 0.1229\n",
            "Epoch 47/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 3.0451 - acc: 0.1348 - val_loss: 2.7688 - val_acc: 0.1314\n",
            "Epoch 48/250\n",
            "178/178 [==============================] - 20s 108ms/step - loss: 3.0772 - acc: 0.1217 - val_loss: 2.7739 - val_acc: 0.1314\n",
            "Epoch 49/250\n",
            "178/178 [==============================] - 19s 104ms/step - loss: 3.0664 - acc: 0.1373 - val_loss: 2.7651 - val_acc: 0.1324\n",
            "Epoch 50/250\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 3.0613 - acc: 0.1281 - val_loss: 2.7594 - val_acc: 0.1356\n",
            "Epoch 51/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 3.0657 - acc: 0.1284 - val_loss: 2.7807 - val_acc: 0.1398\n",
            "Epoch 52/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 3.0696 - acc: 0.1221 - val_loss: 2.7616 - val_acc: 0.1345\n",
            "Epoch 53/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 3.0434 - acc: 0.1186 - val_loss: 2.7431 - val_acc: 0.1398\n",
            "Epoch 54/250\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 3.0197 - acc: 0.1341 - val_loss: 2.7554 - val_acc: 0.1367\n",
            "Epoch 55/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 3.0167 - acc: 0.1348 - val_loss: 2.7406 - val_acc: 0.1345\n",
            "Epoch 56/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 3.0711 - acc: 0.1260 - val_loss: 2.7398 - val_acc: 0.1356\n",
            "Epoch 57/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.9923 - acc: 0.1390 - val_loss: 2.7263 - val_acc: 0.1367\n",
            "Epoch 58/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 2.9830 - acc: 0.1295 - val_loss: 2.7254 - val_acc: 0.1388\n",
            "Epoch 59/250\n",
            "178/178 [==============================] - 25s 136ms/step - loss: 3.0045 - acc: 0.1369 - val_loss: 2.7425 - val_acc: 0.1388\n",
            "Epoch 60/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 3.0127 - acc: 0.1383 - val_loss: 2.7301 - val_acc: 0.1419\n",
            "Epoch 61/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.9868 - acc: 0.1351 - val_loss: 2.7262 - val_acc: 0.1388\n",
            "Epoch 62/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 3.0021 - acc: 0.1299 - val_loss: 2.7084 - val_acc: 0.1462\n",
            "Epoch 63/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.9551 - acc: 0.1443 - val_loss: 2.7180 - val_acc: 0.1430\n",
            "Epoch 64/250\n",
            "178/178 [==============================] - 20s 109ms/step - loss: 2.9690 - acc: 0.1408 - val_loss: 2.6933 - val_acc: 0.1451\n",
            "Epoch 65/250\n",
            "178/178 [==============================] - 19s 104ms/step - loss: 2.9647 - acc: 0.1320 - val_loss: 2.7246 - val_acc: 0.1462\n",
            "Epoch 66/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.9508 - acc: 0.1404 - val_loss: 2.7052 - val_acc: 0.1409\n",
            "Epoch 67/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.9574 - acc: 0.1433 - val_loss: 2.6901 - val_acc: 0.1472\n",
            "Epoch 68/250\n",
            "178/178 [==============================] - 19s 102ms/step - loss: 2.9474 - acc: 0.1397 - val_loss: 2.7000 - val_acc: 0.1504\n",
            "Epoch 69/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.9546 - acc: 0.1288 - val_loss: 2.6986 - val_acc: 0.1462\n",
            "Epoch 70/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.9127 - acc: 0.1496 - val_loss: 2.7005 - val_acc: 0.1472\n",
            "Epoch 71/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.9183 - acc: 0.1341 - val_loss: 2.6914 - val_acc: 0.1483\n",
            "Epoch 72/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.9551 - acc: 0.1418 - val_loss: 2.6937 - val_acc: 0.1504\n",
            "Epoch 73/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.9671 - acc: 0.1426 - val_loss: 2.6886 - val_acc: 0.1547\n",
            "Epoch 74/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.9148 - acc: 0.1450 - val_loss: 2.6672 - val_acc: 0.1515\n",
            "Epoch 75/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.8805 - acc: 0.1524 - val_loss: 2.6801 - val_acc: 0.1451\n",
            "Epoch 76/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.9167 - acc: 0.1450 - val_loss: 2.6652 - val_acc: 0.1504\n",
            "Epoch 77/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 2.9252 - acc: 0.1454 - val_loss: 2.6656 - val_acc: 0.1536\n",
            "Epoch 78/250\n",
            "178/178 [==============================] - 19s 106ms/step - loss: 2.9003 - acc: 0.1426 - val_loss: 2.6701 - val_acc: 0.1504\n",
            "Epoch 79/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 2.8950 - acc: 0.1538 - val_loss: 2.6667 - val_acc: 0.1589\n",
            "Epoch 80/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.9028 - acc: 0.1468 - val_loss: 2.6841 - val_acc: 0.1504\n",
            "Epoch 81/250\n",
            "178/178 [==============================] - 19s 107ms/step - loss: 2.8855 - acc: 0.1436 - val_loss: 2.6462 - val_acc: 0.1536\n",
            "Epoch 82/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.8704 - acc: 0.1429 - val_loss: 2.6511 - val_acc: 0.1504\n",
            "Epoch 83/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.8779 - acc: 0.1542 - val_loss: 2.6442 - val_acc: 0.1504\n",
            "Epoch 84/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.8647 - acc: 0.1510 - val_loss: 2.6508 - val_acc: 0.1525\n",
            "Epoch 85/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.8232 - acc: 0.1471 - val_loss: 2.6610 - val_acc: 0.1610\n",
            "Epoch 86/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.8689 - acc: 0.1546 - val_loss: 2.6507 - val_acc: 0.1557\n",
            "Epoch 87/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.8436 - acc: 0.1563 - val_loss: 2.6485 - val_acc: 0.1557\n",
            "Epoch 88/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.8204 - acc: 0.1591 - val_loss: 2.6711 - val_acc: 0.1536\n",
            "Epoch 89/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.8306 - acc: 0.1464 - val_loss: 2.6594 - val_acc: 0.1525\n",
            "Epoch 90/250\n",
            "178/178 [==============================] - 19s 105ms/step - loss: 2.8766 - acc: 0.1433 - val_loss: 2.6506 - val_acc: 0.1568\n",
            "Epoch 91/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.8595 - acc: 0.1563 - val_loss: 2.6489 - val_acc: 0.1653\n",
            "Epoch 92/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.8159 - acc: 0.1651 - val_loss: 2.6400 - val_acc: 0.1631\n",
            "Epoch 93/250\n",
            "178/178 [==============================] - 20s 109ms/step - loss: 2.8306 - acc: 0.1514 - val_loss: 2.6345 - val_acc: 0.1610\n",
            "Epoch 94/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.8245 - acc: 0.1598 - val_loss: 2.6465 - val_acc: 0.1494\n",
            "Epoch 95/250\n",
            "178/178 [==============================] - 19s 106ms/step - loss: 2.8305 - acc: 0.1408 - val_loss: 2.6575 - val_acc: 0.1568\n",
            "Epoch 96/250\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 2.8388 - acc: 0.1500 - val_loss: 2.6349 - val_acc: 0.1621\n",
            "Epoch 97/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.8338 - acc: 0.1482 - val_loss: 2.6344 - val_acc: 0.1578\n",
            "Epoch 98/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.8157 - acc: 0.1500 - val_loss: 2.6410 - val_acc: 0.1547\n",
            "Epoch 99/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.8331 - acc: 0.1542 - val_loss: 2.6521 - val_acc: 0.1557\n",
            "Epoch 100/250\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 2.7643 - acc: 0.1553 - val_loss: 2.6485 - val_acc: 0.1568\n",
            "Epoch 101/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.7874 - acc: 0.1701 - val_loss: 2.6430 - val_acc: 0.1536\n",
            "Epoch 102/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.8121 - acc: 0.1591 - val_loss: 2.6322 - val_acc: 0.1578\n",
            "Epoch 103/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.7956 - acc: 0.1598 - val_loss: 2.6356 - val_acc: 0.1568\n",
            "Epoch 104/250\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 2.8114 - acc: 0.1570 - val_loss: 2.6327 - val_acc: 0.1557\n",
            "Epoch 105/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.8421 - acc: 0.1475 - val_loss: 2.6302 - val_acc: 0.1600\n",
            "Epoch 106/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.8178 - acc: 0.1503 - val_loss: 2.6261 - val_acc: 0.1578\n",
            "Epoch 107/250\n",
            "178/178 [==============================] - 20s 108ms/step - loss: 2.8030 - acc: 0.1577 - val_loss: 2.6179 - val_acc: 0.1578\n",
            "Epoch 108/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.7635 - acc: 0.1482 - val_loss: 2.6110 - val_acc: 0.1578\n",
            "Epoch 109/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.7851 - acc: 0.1553 - val_loss: 2.6338 - val_acc: 0.1557\n",
            "Epoch 110/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.7526 - acc: 0.1606 - val_loss: 2.6189 - val_acc: 0.1621\n",
            "Epoch 111/250\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 2.7383 - acc: 0.1563 - val_loss: 2.6163 - val_acc: 0.1642\n",
            "Epoch 112/250\n",
            "178/178 [==============================] - 23s 130ms/step - loss: 2.7714 - acc: 0.1620 - val_loss: 2.6033 - val_acc: 0.1568\n",
            "Epoch 113/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.7292 - acc: 0.1658 - val_loss: 2.6075 - val_acc: 0.1547\n",
            "Epoch 114/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.7518 - acc: 0.1588 - val_loss: 2.6157 - val_acc: 0.1525\n",
            "Epoch 115/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.7966 - acc: 0.1588 - val_loss: 2.6169 - val_acc: 0.1547\n",
            "Epoch 116/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.7590 - acc: 0.1673 - val_loss: 2.6146 - val_acc: 0.1568\n",
            "Epoch 117/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.8259 - acc: 0.1447 - val_loss: 2.6164 - val_acc: 0.1663\n",
            "Epoch 118/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.7583 - acc: 0.1531 - val_loss: 2.6075 - val_acc: 0.1621\n",
            "Epoch 119/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.7243 - acc: 0.1538 - val_loss: 2.6069 - val_acc: 0.1589\n",
            "Epoch 120/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.7474 - acc: 0.1591 - val_loss: 2.6023 - val_acc: 0.1568\n",
            "Epoch 121/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.7253 - acc: 0.1754 - val_loss: 2.6136 - val_acc: 0.1589\n",
            "Epoch 122/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.6930 - acc: 0.1616 - val_loss: 2.6081 - val_acc: 0.1568\n",
            "Epoch 123/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.6999 - acc: 0.1662 - val_loss: 2.5999 - val_acc: 0.1631\n",
            "Epoch 124/250\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 2.7425 - acc: 0.1581 - val_loss: 2.6113 - val_acc: 0.1621\n",
            "Epoch 125/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.7255 - acc: 0.1542 - val_loss: 2.6071 - val_acc: 0.1695\n",
            "Epoch 126/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.7605 - acc: 0.1574 - val_loss: 2.6021 - val_acc: 0.1589\n",
            "Epoch 127/250\n",
            "178/178 [==============================] - 19s 101ms/step - loss: 2.7230 - acc: 0.1630 - val_loss: 2.6106 - val_acc: 0.1621\n",
            "Epoch 128/250\n",
            "178/178 [==============================] - 19s 107ms/step - loss: 2.7128 - acc: 0.1627 - val_loss: 2.5952 - val_acc: 0.1631\n",
            "Epoch 129/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.7214 - acc: 0.1641 - val_loss: 2.6091 - val_acc: 0.1674\n",
            "Epoch 130/250\n",
            "178/178 [==============================] - 20s 108ms/step - loss: 2.6828 - acc: 0.1655 - val_loss: 2.6056 - val_acc: 0.1674\n",
            "Epoch 131/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.7284 - acc: 0.1535 - val_loss: 2.6066 - val_acc: 0.1642\n",
            "Epoch 132/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.7215 - acc: 0.1577 - val_loss: 2.5987 - val_acc: 0.1663\n",
            "Epoch 133/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.7137 - acc: 0.1591 - val_loss: 2.5968 - val_acc: 0.1706\n",
            "Epoch 134/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.7148 - acc: 0.1722 - val_loss: 2.6049 - val_acc: 0.1600\n",
            "Epoch 135/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.7206 - acc: 0.1595 - val_loss: 2.5869 - val_acc: 0.1653\n",
            "Epoch 136/250\n",
            "178/178 [==============================] - 24s 129ms/step - loss: 2.7029 - acc: 0.1634 - val_loss: 2.6012 - val_acc: 0.1674\n",
            "Epoch 137/250\n",
            "178/178 [==============================] - 20s 108ms/step - loss: 2.6877 - acc: 0.1644 - val_loss: 2.5911 - val_acc: 0.1684\n",
            "Epoch 138/250\n",
            "178/178 [==============================] - 20s 106ms/step - loss: 2.7047 - acc: 0.1560 - val_loss: 2.6063 - val_acc: 0.1610\n",
            "Epoch 139/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.7138 - acc: 0.1757 - val_loss: 2.6005 - val_acc: 0.1621\n",
            "Epoch 140/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.7018 - acc: 0.1740 - val_loss: 2.5896 - val_acc: 0.1684\n",
            "Epoch 141/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.7013 - acc: 0.1606 - val_loss: 2.5925 - val_acc: 0.1727\n",
            "Epoch 142/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.6873 - acc: 0.1634 - val_loss: 2.6027 - val_acc: 0.1716\n",
            "Epoch 143/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.6707 - acc: 0.1673 - val_loss: 2.5966 - val_acc: 0.1684\n",
            "Epoch 144/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.6714 - acc: 0.1743 - val_loss: 2.5973 - val_acc: 0.1695\n",
            "Epoch 145/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.6547 - acc: 0.1736 - val_loss: 2.5809 - val_acc: 0.1663\n",
            "Epoch 146/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.6651 - acc: 0.1584 - val_loss: 2.5901 - val_acc: 0.1748\n",
            "Epoch 147/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.6510 - acc: 0.1680 - val_loss: 2.6094 - val_acc: 0.1790\n",
            "Epoch 148/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.6817 - acc: 0.1655 - val_loss: 2.5910 - val_acc: 0.1695\n",
            "Epoch 149/250\n",
            "178/178 [==============================] - 19s 102ms/step - loss: 2.6508 - acc: 0.1715 - val_loss: 2.5969 - val_acc: 0.1674\n",
            "Epoch 150/250\n",
            "178/178 [==============================] - 24s 129ms/step - loss: 2.6529 - acc: 0.1722 - val_loss: 2.6095 - val_acc: 0.1727\n",
            "Epoch 151/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.6127 - acc: 0.1761 - val_loss: 2.5951 - val_acc: 0.1790\n",
            "Epoch 152/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.6436 - acc: 0.1658 - val_loss: 2.6001 - val_acc: 0.1758\n",
            "Epoch 153/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.6540 - acc: 0.1743 - val_loss: 2.5830 - val_acc: 0.1737\n",
            "Epoch 154/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.6229 - acc: 0.1764 - val_loss: 2.6128 - val_acc: 0.1653\n",
            "Epoch 155/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.6375 - acc: 0.1761 - val_loss: 2.5869 - val_acc: 0.1769\n",
            "Epoch 156/250\n",
            "178/178 [==============================] - 25s 136ms/step - loss: 2.6541 - acc: 0.1655 - val_loss: 2.5951 - val_acc: 0.1801\n",
            "Epoch 157/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.6677 - acc: 0.1824 - val_loss: 2.5802 - val_acc: 0.1758\n",
            "Epoch 158/250\n",
            "178/178 [==============================] - 19s 106ms/step - loss: 2.6508 - acc: 0.1761 - val_loss: 2.5936 - val_acc: 0.1716\n",
            "Epoch 159/250\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 2.6526 - acc: 0.1754 - val_loss: 2.5787 - val_acc: 0.1780\n",
            "Epoch 160/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.6202 - acc: 0.1750 - val_loss: 2.5967 - val_acc: 0.1811\n",
            "Epoch 161/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.6337 - acc: 0.1803 - val_loss: 2.5772 - val_acc: 0.1748\n",
            "Epoch 162/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.6167 - acc: 0.1706 - val_loss: 2.5942 - val_acc: 0.1769\n",
            "Epoch 163/250\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 2.6018 - acc: 0.1771 - val_loss: 2.5974 - val_acc: 0.1727\n",
            "Epoch 164/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.6401 - acc: 0.1740 - val_loss: 2.6016 - val_acc: 0.1780\n",
            "Epoch 165/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.6706 - acc: 0.1722 - val_loss: 2.5820 - val_acc: 0.1758\n",
            "Epoch 166/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.6325 - acc: 0.1810 - val_loss: 2.5905 - val_acc: 0.1769\n",
            "Epoch 167/250\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 2.6387 - acc: 0.1757 - val_loss: 2.5911 - val_acc: 0.1769\n",
            "Epoch 168/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.6417 - acc: 0.1733 - val_loss: 2.5964 - val_acc: 0.1748\n",
            "Epoch 169/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.5968 - acc: 0.1743 - val_loss: 2.6048 - val_acc: 0.1769\n",
            "Epoch 170/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.6274 - acc: 0.1676 - val_loss: 2.5863 - val_acc: 0.1748\n",
            "Epoch 171/250\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 2.5995 - acc: 0.1874 - val_loss: 2.5851 - val_acc: 0.1896\n",
            "Epoch 172/250\n",
            "178/178 [==============================] - 19s 102ms/step - loss: 2.6350 - acc: 0.1655 - val_loss: 2.5929 - val_acc: 0.1801\n",
            "Epoch 173/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.6417 - acc: 0.1651 - val_loss: 2.6004 - val_acc: 0.1769\n",
            "Epoch 174/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.5984 - acc: 0.1740 - val_loss: 2.5874 - val_acc: 0.1854\n",
            "Epoch 175/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.6144 - acc: 0.1673 - val_loss: 2.5952 - val_acc: 0.1822\n",
            "Epoch 176/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.6001 - acc: 0.1750 - val_loss: 2.5986 - val_acc: 0.1790\n",
            "Epoch 177/250\n",
            "178/178 [==============================] - 20s 108ms/step - loss: 2.6262 - acc: 0.1821 - val_loss: 2.5677 - val_acc: 0.1875\n",
            "Epoch 178/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.5996 - acc: 0.1838 - val_loss: 2.5846 - val_acc: 0.1801\n",
            "Epoch 179/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.5815 - acc: 0.1870 - val_loss: 2.5942 - val_acc: 0.1822\n",
            "Epoch 180/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.6122 - acc: 0.1658 - val_loss: 2.6043 - val_acc: 0.1864\n",
            "Epoch 181/250\n",
            "178/178 [==============================] - 20s 111ms/step - loss: 2.6201 - acc: 0.1718 - val_loss: 2.5860 - val_acc: 0.1790\n",
            "Epoch 182/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.5815 - acc: 0.1803 - val_loss: 2.6040 - val_acc: 0.1758\n",
            "Epoch 183/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.5438 - acc: 0.1888 - val_loss: 2.5954 - val_acc: 0.1790\n",
            "Epoch 184/250\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 2.5847 - acc: 0.1814 - val_loss: 2.6055 - val_acc: 0.1780\n",
            "Epoch 185/250\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 2.6080 - acc: 0.1665 - val_loss: 2.6065 - val_acc: 0.1811\n",
            "Epoch 186/250\n",
            "178/178 [==============================] - 20s 109ms/step - loss: 2.6010 - acc: 0.1736 - val_loss: 2.6045 - val_acc: 0.1833\n",
            "Epoch 187/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.5912 - acc: 0.1771 - val_loss: 2.5921 - val_acc: 0.1843\n",
            "Epoch 188/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.5979 - acc: 0.1655 - val_loss: 2.6064 - val_acc: 0.1801\n",
            "Epoch 189/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.6019 - acc: 0.1785 - val_loss: 2.5876 - val_acc: 0.1843\n",
            "Epoch 190/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.5836 - acc: 0.1817 - val_loss: 2.5975 - val_acc: 0.1822\n",
            "Epoch 191/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.5827 - acc: 0.1793 - val_loss: 2.6015 - val_acc: 0.1833\n",
            "Epoch 192/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.5621 - acc: 0.1793 - val_loss: 2.5995 - val_acc: 0.1758\n",
            "Epoch 193/250\n",
            "178/178 [==============================] - 20s 107ms/step - loss: 2.5552 - acc: 0.1743 - val_loss: 2.6000 - val_acc: 0.1822\n",
            "Epoch 194/250\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 2.6007 - acc: 0.1634 - val_loss: 2.5827 - val_acc: 0.1833\n",
            "Epoch 195/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.5396 - acc: 0.1831 - val_loss: 2.5718 - val_acc: 0.1854\n",
            "Epoch 196/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.5728 - acc: 0.1800 - val_loss: 2.5883 - val_acc: 0.1843\n",
            "Epoch 197/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.5384 - acc: 0.1898 - val_loss: 2.6057 - val_acc: 0.1780\n",
            "Epoch 198/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.5502 - acc: 0.1729 - val_loss: 2.6087 - val_acc: 0.1854\n",
            "Epoch 199/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.6005 - acc: 0.1761 - val_loss: 2.6065 - val_acc: 0.1822\n",
            "Epoch 200/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.5957 - acc: 0.1715 - val_loss: 2.6148 - val_acc: 0.1833\n",
            "Epoch 201/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.5364 - acc: 0.1849 - val_loss: 2.5960 - val_acc: 0.1864\n",
            "Epoch 202/250\n",
            "178/178 [==============================] - 19s 106ms/step - loss: 2.5778 - acc: 0.1778 - val_loss: 2.5893 - val_acc: 0.1833\n",
            "Epoch 203/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.5390 - acc: 0.1888 - val_loss: 2.5796 - val_acc: 0.1886\n",
            "Epoch 204/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 2.5592 - acc: 0.1729 - val_loss: 2.5861 - val_acc: 0.1801\n",
            "Epoch 205/250\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 2.5490 - acc: 0.1796 - val_loss: 2.5885 - val_acc: 0.1811\n",
            "Epoch 206/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.5517 - acc: 0.1803 - val_loss: 2.6107 - val_acc: 0.1801\n",
            "Epoch 207/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.5422 - acc: 0.1969 - val_loss: 2.6165 - val_acc: 0.1843\n",
            "Epoch 208/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.5618 - acc: 0.1849 - val_loss: 2.6005 - val_acc: 0.1854\n",
            "Epoch 209/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.5571 - acc: 0.1810 - val_loss: 2.5882 - val_acc: 0.1907\n",
            "Epoch 210/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.5068 - acc: 0.1870 - val_loss: 2.5848 - val_acc: 0.1896\n",
            "Epoch 211/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.5363 - acc: 0.1912 - val_loss: 2.5856 - val_acc: 0.1854\n",
            "Epoch 212/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.5338 - acc: 0.1856 - val_loss: 2.5950 - val_acc: 0.1886\n",
            "Epoch 213/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.5176 - acc: 0.1884 - val_loss: 2.6188 - val_acc: 0.1843\n",
            "Epoch 214/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.5215 - acc: 0.1888 - val_loss: 2.5955 - val_acc: 0.1854\n",
            "Epoch 215/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.5551 - acc: 0.1750 - val_loss: 2.6157 - val_acc: 0.1822\n",
            "Epoch 216/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.5324 - acc: 0.1870 - val_loss: 2.6083 - val_acc: 0.1843\n",
            "Epoch 217/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.5058 - acc: 0.1888 - val_loss: 2.6208 - val_acc: 0.1780\n",
            "Epoch 218/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.5141 - acc: 0.1888 - val_loss: 2.6208 - val_acc: 0.1769\n",
            "Epoch 219/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.5347 - acc: 0.1810 - val_loss: 2.6050 - val_acc: 0.1854\n",
            "Epoch 220/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.5313 - acc: 0.1789 - val_loss: 2.5884 - val_acc: 0.1854\n",
            "Epoch 221/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 2.4983 - acc: 0.1941 - val_loss: 2.5952 - val_acc: 0.1928\n",
            "Epoch 222/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.5133 - acc: 0.1912 - val_loss: 2.5986 - val_acc: 0.1843\n",
            "Epoch 223/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.5043 - acc: 0.1817 - val_loss: 2.5983 - val_acc: 0.1928\n",
            "Epoch 224/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.5274 - acc: 0.1775 - val_loss: 2.6049 - val_acc: 0.1875\n",
            "Epoch 225/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.5371 - acc: 0.1874 - val_loss: 2.5967 - val_acc: 0.1875\n",
            "Epoch 226/250\n",
            "178/178 [==============================] - 19s 105ms/step - loss: 2.4854 - acc: 0.2022 - val_loss: 2.5959 - val_acc: 0.1875\n",
            "Epoch 227/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.5019 - acc: 0.1951 - val_loss: 2.5960 - val_acc: 0.1896\n",
            "Epoch 228/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.5051 - acc: 0.1937 - val_loss: 2.5754 - val_acc: 0.1843\n",
            "Epoch 229/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.5281 - acc: 0.1871 - val_loss: 2.5865 - val_acc: 0.1801\n",
            "Epoch 230/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.5119 - acc: 0.1867 - val_loss: 2.5761 - val_acc: 0.1822\n",
            "Epoch 231/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.5485 - acc: 0.1761 - val_loss: 2.5839 - val_acc: 0.1939\n",
            "Epoch 232/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 2.5069 - acc: 0.1669 - val_loss: 2.5862 - val_acc: 0.1907\n",
            "Epoch 233/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.5040 - acc: 0.1807 - val_loss: 2.5812 - val_acc: 0.1854\n",
            "Epoch 234/250\n",
            "178/178 [==============================] - 19s 103ms/step - loss: 2.4833 - acc: 0.1965 - val_loss: 2.5642 - val_acc: 0.1864\n",
            "Epoch 235/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.4828 - acc: 0.1905 - val_loss: 2.5725 - val_acc: 0.1949\n",
            "Epoch 236/250\n",
            "178/178 [==============================] - 23s 130ms/step - loss: 2.4992 - acc: 0.1905 - val_loss: 2.6019 - val_acc: 0.1875\n",
            "Epoch 237/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 2.5139 - acc: 0.1845 - val_loss: 2.5960 - val_acc: 0.1886\n",
            "Epoch 238/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.5041 - acc: 0.1937 - val_loss: 2.6062 - val_acc: 0.1928\n",
            "Epoch 239/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.4654 - acc: 0.1994 - val_loss: 2.5998 - val_acc: 0.1864\n",
            "Epoch 240/250\n",
            "178/178 [==============================] - 23s 126ms/step - loss: 2.5098 - acc: 0.1747 - val_loss: 2.6191 - val_acc: 0.1886\n",
            "Epoch 241/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.4606 - acc: 0.1972 - val_loss: 2.5964 - val_acc: 0.1801\n",
            "Epoch 242/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.4957 - acc: 0.1870 - val_loss: 2.5869 - val_acc: 0.1833\n",
            "Epoch 243/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 2.4984 - acc: 0.1891 - val_loss: 2.5845 - val_acc: 0.1822\n",
            "Epoch 244/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.5075 - acc: 0.1912 - val_loss: 2.6002 - val_acc: 0.1875\n",
            "Epoch 245/250\n",
            "178/178 [==============================] - 19s 102ms/step - loss: 2.4702 - acc: 0.1951 - val_loss: 2.5893 - val_acc: 0.1907\n",
            "Epoch 246/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.4870 - acc: 0.1895 - val_loss: 2.5964 - val_acc: 0.1917\n",
            "Epoch 247/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 2.4783 - acc: 0.1824 - val_loss: 2.6134 - val_acc: 0.1833\n",
            "Epoch 248/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.4644 - acc: 0.2001 - val_loss: 2.6103 - val_acc: 0.1864\n",
            "Epoch 249/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.4598 - acc: 0.1916 - val_loss: 2.5932 - val_acc: 0.1896\n",
            "Epoch 250/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.4837 - acc: 0.1856 - val_loss: 2.5833 - val_acc: 0.1864\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(learning_rate=2e-5),\n",
        "              metrics=['acc'])\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Y3K89-CM-dfg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "dcfc527d-cf10-4b9e-f657-1ae4dda60ded"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_x = range(len(acc))\n",
        "\n",
        "plt.plot(epochs_x, acc, 'ro', label='Training acc')\n",
        "plt.plot(epochs_x, val_acc, 'k', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_x, loss, 'ro', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R19IJQSYoW7J"
      },
      "source": [
        "#Download the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Zed4TdFcG2iJ"
      },
      "outputs": [],
      "source": [
        "os.makedirs('/content/drive/My Drive/cut_panoramic/Model', exist_ok=True)\n",
        "model.save('/content/drive/MyDrive/cut_panoramic/Model/Classification/All_Age/(2e-5)1_AC1_AllAge_Freeze_250.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "P5eMxm1NV-oY"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# files.download('/content/drive/My Drive/cut_panoramic/Model/1_รอบแรก_Gender_250.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "xlsuaFIUVriv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}